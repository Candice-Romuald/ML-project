{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "library(caret)\n",
    "library(keras)\n",
    "use_condaenv(\"r-tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first prepare our training data, note that we remove all highly correlated predictors as it has prooved to be useful. We used a cutoff value of 0.7 as papers suggest that a correlation coefficient higher than 0.7 means that predictors are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- read.csv(file = '../../Data/training_data.csv')\n",
    "train <- subset(train,select = -SWEETORSOUR)\n",
    "train$Intensity <- as.numeric(train$Intensity)\n",
    "Y <- train$VALENCE.PLEASANTNESS\n",
    "train <- subset(train,select = -VALENCE.PLEASANTNESS)\n",
    "train.Z <- subset(train,select = -nearZeroVar(train))\n",
    "correlation <- cor(train.Z)\n",
    "id <- sort(findCorrelation(correlation, cutoff=0.7))\n",
    "data.unC <- train.Z[,-id]\n",
    "X <- as.matrix(data.unC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a small, one-layer neural network to get a feeling for how well a neural network works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAP1BMVEUAAAAAv8QzMzNNTU1o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\nkiQ10P8D1R0/CselnswAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn <- keras_model_sequential()\n",
    "\n",
    "nn %>%\n",
    " layer_dense(units = 50,  activation = 'relu', kernel_initializer = \"he_normal\", input_shape = 196)  %>%\n",
    " layer_dense(units = 1,activation = 'linear')\n",
    "\n",
    "nn %>% compile(\n",
    "  loss = 'mse',\n",
    "  optimizer = 'adam'\n",
    ")\n",
    "\n",
    "history <- nn %>% fit(\n",
    "  (X), Y, \n",
    "  epochs = 200,\n",
    "  validation_split = 0.5,\n",
    "  callbacks = callback_early_stopping(monitor = \"val_loss\", patience = 20)\n",
    ")\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the result is very average. We are now going to appropriately scale the data before fitting other neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "library(caret)\n",
    "library(keras)\n",
    "library(MASS)\n",
    "library(ggfortify)\n",
    "use_condaenv(\"r-tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- read.csv(file = '../../Data/training_data.csv')\n",
    "train <- subset(train,select = -SWEETORSOUR)\n",
    "train$Intensity <- as.numeric(train$Intensity)\n",
    "train.Z <- subset(train,select = -nearZeroVar(train))\n",
    "correlation <- cor(train.Z)\n",
    "id <- sort(findCorrelation(correlation, cutoff=0.5))\n",
    "data.unC <- train.Z[,-id]\n",
    "\n",
    "#Splitting the data into a training and a validation set to simulate a test set\n",
    "idx.train <- sample(nrow(data.unC), nrow(data.unC)*0.6)\n",
    "Y <- train[idx.train,]$VALENCE.PLEASANTNESS\n",
    "y.valid <- train[-idx.train,]$VALENCE.PLEASANTNESS\n",
    "data.unC <- subset(data.unC,select = -VALENCE.PLEASANTNESS)\n",
    "X <- data.unC[idx.train,]\n",
    "X <- as.matrix(X)\n",
    "x.valid <- data.unC[-idx.train,]\n",
    "x.valid <- as.matrix(x.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling methods\n",
    "get.scale <- function(scaled) {\n",
    "    if (\"scaled:center\" %in% names(attributes(scaled))) {\n",
    "        center <- attr(scaled, \"scaled:center\")\n",
    "    } else {\n",
    "        center <- rep(0, ncol(scaled))\n",
    "    }\n",
    "    if (\"scaled:scale\" %in% names(attributes(scaled))) {\n",
    "        list(center, attr(scaled, \"scaled:scale\"))\n",
    "    } else {\n",
    "        list(center, rep(1., length(center)))\n",
    "    }\n",
    "}\n",
    "x.scale <- function(x, scaled) {\n",
    "    s <- get.scale(scaled)\n",
    "    centered <- sweep(x, 2, s[[1]])\n",
    "    sweep(centered, 2, s[[2]], FUN = \"/\")\n",
    "}\n",
    "y.scale <- function(y, scaled) {\n",
    "    s <- get.scale(scaled)\n",
    "    (y - s[[1]])/s[[2]]\n",
    "}\n",
    "y.unscale <- function(y, scaled) {\n",
    "    s <- get.scale(scaled)\n",
    "    y * s[[2]] + s[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.scaled <- scale(X,center = T, scale = T)\n",
    "y.scaled <- scale(Y,center = T, scale = T)\n",
    "x.valid.scaled <- x.scale(x.valid,x.scaled)\n",
    "y.valid.scaled <- y.scale(y.valid,y.scaled)\n",
    "\n",
    "\n",
    "#A function to test hyper parameters combinations\n",
    "Neural_testing <- function(a = c(10,30,100),b = c(10,30,100), regul = c(0.1,0.01), drop = 0.6)){\n",
    "    output <- c(1,1,1,1,100)\n",
    "    for(i in a){\n",
    "        for(j in b){\n",
    "            for(z in regul){\n",
    "                for(c in drop){\n",
    "                    nn <- keras_model_sequential()\n",
    "\n",
    "                    nn %>%\n",
    "                     layer_dense(i,kernel_regularizer = regularizer_l2(l = z), activation = \"relu\", input_shape = c(dim(X)[2])) %>%\n",
    "                     layer_dropout(rate = c) %>%\n",
    "                     layer_dense(j, kernel_regularizer = regularizer_l2(l = z), activation = \"relu\") %>%\n",
    "                     layer_dropout(rate = c) %>%\n",
    "                     layer_dense(1, activation = \"linear\")\n",
    "\n",
    "                    nn %>% compile(\n",
    "                      loss = 'mse',\n",
    "                      optimizer = 'adam'\n",
    "                    )\n",
    "\n",
    "                    history <- nn %>% fit(\n",
    "                      (x.scaled), y.scaled, \n",
    "                      epochs = 1000,\n",
    "                      validation_split = 0.5,\n",
    "                      callbacks = callback_early_stopping(monitor = \"val_loss\", patience = 50)\n",
    "                    )\n",
    "\n",
    "                    nn.pred <- predict(nn, x.valid.scaled)\n",
    "                    cat(\"Layer 1: \", i, \"Layer 2: \", j, \"error: \", sqrt(mean((y.unscale(nn.pred, y.scaled) - y.valid)^2)), \"\\n\")\n",
    "                    temp <- c(i,j,z,c,sqrt(mean((y.unscale(nn.pred, y.scaled) - y.valid)^2)))\n",
    "                    if(temp[5]<output[5]){\n",
    "                        output <- temp\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    output\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:  10 Layer 2:  10 error:  22.41182 \n",
      "Layer 1:  10 Layer 2:  10 error:  22.02303 \n",
      "Layer 1:  10 Layer 2:  10 error:  23.60649 \n",
      "Layer 1:  10 Layer 2:  10 error:  22.45232 \n",
      "Layer 1:  10 Layer 2:  30 error:  23.1173 \n",
      "Layer 1:  10 Layer 2:  30 error:  21.71314 \n",
      "Layer 1:  10 Layer 2:  30 error:  23.16781 \n",
      "Layer 1:  10 Layer 2:  30 error:  22.2653 \n",
      "Layer 1:  10 Layer 2:  100 error:  23.21534 \n",
      "Layer 1:  10 Layer 2:  100 error:  21.77309 \n",
      "Layer 1:  10 Layer 2:  100 error:  23.24821 \n",
      "Layer 1:  10 Layer 2:  100 error:  21.80139 \n",
      "Layer 1:  30 Layer 2:  10 error:  22.92885 \n",
      "Layer 1:  30 Layer 2:  10 error:  21.74964 \n",
      "Layer 1:  30 Layer 2:  10 error:  23.57267 \n",
      "Layer 1:  30 Layer 2:  10 error:  21.74489 \n",
      "Layer 1:  30 Layer 2:  30 error:  22.59521 \n",
      "Layer 1:  30 Layer 2:  30 error:  22.00372 \n",
      "Layer 1:  30 Layer 2:  30 error:  24.16335 \n",
      "Layer 1:  30 Layer 2:  30 error:  22.69851 \n",
      "Layer 1:  30 Layer 2:  100 error:  23.14448 \n",
      "Layer 1:  30 Layer 2:  100 error:  22.63977 \n",
      "Layer 1:  30 Layer 2:  100 error:  24.97429 \n",
      "Layer 1:  30 Layer 2:  100 error:  22.23023 \n",
      "Layer 1:  100 Layer 2:  10 error:  23.20395 \n",
      "Layer 1:  100 Layer 2:  10 error:  22.29339 \n",
      "Layer 1:  100 Layer 2:  10 error:  23.48336 \n",
      "Layer 1:  100 Layer 2:  10 error:  21.97309 \n",
      "Layer 1:  100 Layer 2:  30 error:  23.2782 \n",
      "Layer 1:  100 Layer 2:  30 error:  22.46011 \n",
      "Layer 1:  100 Layer 2:  30 error:  24.21444 \n",
      "Layer 1:  100 Layer 2:  30 error:  23.49022 \n",
      "Layer 1:  100 Layer 2:  100 error:  23.50404 \n",
      "Layer 1:  100 Layer 2:  100 error:  22.49642 \n",
      "Layer 1:  100 Layer 2:  100 error:  24.8989 \n",
      "Layer 1:  100 Layer 2:  100 error:  23.71473 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>10</li>\n",
       "\t<li>30</li>\n",
       "\t<li>0.1</li>\n",
       "\t<li>0.6</li>\n",
       "\t<li>21.7131417070264</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 10\n",
       "\\item 30\n",
       "\\item 0.1\n",
       "\\item 0.6\n",
       "\\item 21.7131417070264\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 10\n",
       "2. 30\n",
       "3. 0.1\n",
       "4. 0.6\n",
       "5. 21.7131417070264\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 10.00000 30.00000  0.10000  0.60000 21.71314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Neural_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this testing run we conclude that the best hyperparameters would be a neural network with 2 hidden layers of 10 and 30 neurons, both of which are l2 regularized with a value of 0.1 and have a 0.6 (60%!!) dropout rate.  As expected the network must be tightly regularized to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results <- predict(nn, boston.x.scale(x.testa, boston.train.x.prep))\n",
    "#results <- boston.y.unscale(results,boston.train.y.prep)\n",
    "#id <- 1:68\n",
    "#temps <- data.frame(results)\n",
    "#final.data <- data.frame(Id = id, VALENCE.PLEASANTNESS = temps$results)\n",
    "#write_csv(final.data, \"../../Submission/NNopti.csv\", row.names=FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
